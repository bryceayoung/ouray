---
title: "pixel_metrics"
author: "Bryce A Young"
date: "2024-10-02"
modified: "2025-01-29"
output: html_document
---

Overview: this markdown file follows the other rmd files `lidar_exploration.rmd` and `las_normalization.rmd`. In those files, I explored the data, and then normalized the heights, creating a las catalog that is at the following path: "F:/_BRYCE/LiDAR/Ouray_County/las_normalized_catalog".

In this document, I will use the normalized catalog to create rasters that represent the forest canopy across various parameters. 

First, we're going to do a las_check() on some of the files to see if there are certain points that we should withhold when creating rasters. There may be data cleaning required.
```{r}

data_path <- "D:/_PROJECTS/P001_OurayParcel/data"
ctg_path <- file.path(data_path, "las_normalized_catalog")
out_path <- file.path(data_path, "tiffs_from_las")
scratch <- file.path(data_path, "_temp")

```

Load the correct packages

```{r}

library(terra)
library(sf)
library(sp)
library(raster)
library(lidR)
library(RColorBrewer)

```

Now we can read in the las catalog! This will take a few minutes.

```{r}

# Identify catalog
ctg <- readLAScatalog(ctg_path, filter = '-drop_withheld -drop_class 18 -keep_z -1 40')

```

Now we're going to do a las_check on a few random files. Let's do it by index, and take 250, 500, 750 and 1000.

```{r}

test1 <- readLAS(ctg$filename[250])
test2 <- readLAS(ctg$filename[500])
test3 <- readLAS(ctg$filename[750])
test4 <- readLAS(ctg$filename[1000])

las_check(test1)
las_check(test2)
las_check(test3)
las_check(test4)

las_check(ctg)

```

For each of the test objects, and all of the other tests I did in previous rmd files, we see two primary issues: (1) pulses (points with the same gpstime) have points with identical ReturnNumber, (2) points below 0. The number of points below 0 are in the tens of thousands domain, and the gpstime pulses are in the hundreds or the thousands domain.

Additionally, `las_check(ctg)` revealed that all the files have points below 0, there is an inconsistent CRS across files, and apparently the files aren't normalized, even though I just normalized them. 

Until I get these resolved, I'm going to create canopy height models with my test objects and plot them for quality check.

```{r}

# Define color palette
col <- brewer.pal(5, "Reds")

# Define CRS
crs = CRS("EPSG:26913")

chm1 <- rasterize_canopy(test1, res=1, algorithm=p2r(), crs=crs)
chm2 <- rasterize_canopy(test2, res=1, algorithm=p2r(), crs=crs)
chm3 <- rasterize_canopy(test3, res=1, algorithm=p2r(), crs=crs)
chm4 <- rasterize_canopy(test4, res=1, algorithm=p2r(), crs=crs)

plot(chm4, col=col)

```

Now we are going to print the crs to make sure it was assigned correctly, and we're going to save the files to the `_temp` folder where we can again verify this in ArcGIS.

I ran `terra::crs(chm1)` in the R terminal and can see that the desired EPSG was not assigned.
It still has the vertical component that I want to get rid of.
So below, we're going to try to change this.

```{r}

terra::crs(chm1) <- CRS("EPSG:26913")
print(terra::crs(chm1))

```

That worked! So let's save this as a file and view in ArcGIS to make sure that the changes were applied.

```{r}

writeRaster(chm1, file.path(scratch, "chm1.tif"))

```

Great, the good news is that it appears in ArcGIS and is assigned the correct CRS!
Now we're just going to be extra sure about this by checking out the raster in Python.
Everything looks good. Now let's apply that exact same code to the full county CRS.

```{r}

chm <- rasterize_canopy(ctg, res=1, algorithm=p2r())
terra::crs(chm) <- CRS("EPSG:26913")

print(terra::crs(chm))
```

```{r}
writeRaster(chm, file.path(out_path, "chm.tif"))

plot(chm, col=col)

```

Creating a CHM from the entire catalog with LZW compression will take about 1-2hrs.

Now we are going to create more rasters from the catalog! Here are the `pixel_metrics()` that I'm going to get:

- `zqx` : xth percentile (quantile) of height distribution
- `zentropy` : entropy of height distribution
- `itot` : sum of intensities for each return
- `imax` : max intensity
- `imean` : mean intensity
- `ip1st` : percentage of intensity returned by 1st returns

The intensity metrics can possibly help us segment buildings. The zentropy may give us insights to ladder fuels, the percentiles of height distribution can help us classify groups of building types. All will be interesting to see and explore on a map!

Don't run the code block below. This is great for single tiles but takes days for the entire county.

```{r}

start_time <- proc.time()

# Calculate standard metrics
metrics <- pixel_metrics(ctg, .stdmetrics, 1)

end_time <- proc.time() - start_time
# Convert elapsed time to seconds
total_seconds <- end_time["elapsed"]

# Convert to hours, minutes, and seconds
hours <- floor(total_seconds / 3600)
minutes <- floor((total_seconds %% 3600) / 60)
seconds <- round(total_seconds %% 60)

message(sprintf("Metrics took %d hours, %d minutes, and %d seconds to produce!", hours, minutes, seconds))

```

TESTING FUNCTIONS AND THEIR UTILITY

```{r}
# OPTIONAL: read catalog again
# ctg <- readLAScatalog("F:/_BRYCE/LiDAR/Ouray_County/las_normalized_catalog/", filter = '-drop_withheld -drop_class 18 -keep_z -1 40')

# Run these individually

las <- readLAS(file.path(ctg_path, "usgs_lpc_co_sanluisjuanmiguel_2020_d20_13s_bc_6413_normalized.las"), filter = '-drop_withheld -drop_class 18 -keep_z -1 40')

zentropy <- pixel_metrics(las, ~entropy(Z, by=2), res=1) # Entropy of z values
itot <- pixel_metrics(las, ~sum(Intensity), res=1)  # Sum of intensity of all returns
imax <- pixel_metrics(las, ~max(Intensity), res=1)   # Max intensity
imean <- pixel_metrics(las, ~mean(Intensity), res=1) # Mean intensity

terra::crs(zentropy) <- CRS("EPSG:26913")
terra::crs(itot) <- CRS("EPSG:26913")
terra::crs(imean) <- CRS("EPSG:26913")
terra::crs(imax) <- CRS("EPSG:26913")

```
Let's save these as tiffs and look at them in ArcGIS. 

```{r}

terra::crs(zentropy) <- "EPSG:26913"
print(terra::crs(zentropy))

```


```{r}

writeRaster(imax, file.path(scratch, "imax_test_WKID26913.tif"))
writeRaster(imean, file.path(scratch, "imean_test_WKID26913.tif"))
writeRaster(itot, file.path(scratch, "itot_test_WKID26913.tif"))
writeRaster(zentropy, file.path(scratch, "zentropy_test_WKID26913.tif"))

```

Viewing in ArcGIS, you can see that there is not much information in the intensity rasters. However, `zentropy` seems very promising for segmenting objects, including both buildings and trees. So let's run that function on the entire catalog.

```{r}
start_time <- proc.time()



###########################################

# Define catalog
ctg <- readLAScatalog(ctg_path, filter = '-drop_withheld -drop_class 18 -keep_z -1 40')
# Run function
zentropy <- pixel_metrics(ctg, ~entropy(Z), res=1)
terra::crs(zentropy) <- "EPSG:26913"

# Write raster
writeRaster(zentropy, file.path(out_path, "zentropy_WKID26913.tif"))


###########################################



end_time <- proc.time() - start_time
# Convert elapsed time to seconds
total_seconds <- end_time["elapsed"]

# Convert to hours, minutes, and seconds
hours <- floor(total_seconds / 3600)
minutes <- floor((total_seconds %% 3600) / 60)
seconds <- round(total_seconds %% 60)

message(sprintf("Z-Entropy took %d hours, %d minutes, and %d seconds to produce and save to file!", hours, minutes, seconds))

```

1st run on UM lab computer:
Z-Entropy took 11 hours, 34 minutes, and 39 seconds to produce and save to file!

2nd run on Waffle (personal PC in Red Lodge):
AMD Ryzen 9 9950X 16-Core Processor (4.30 GHz), 128GB RAM, NVIDIA GeForce 3080 GPU
**Z-Entropy took 3 hours, 1 minutes, and 19 seconds to produce and save to file!**

Now I want to make a binary raster where pixels are 0 or 1 if z values [ 0 < Z <= 2 ] are absent or present, respectively. 

```{r}
start_time <- proc.time()

# Create a custom function to classify pixels based on the Z value
custom_classification <- function(z) {
  return(as.integer(any(z > 0 & z <= 2)))  # 1 if any point is in the range, otherwise 0
}

###########################################
# Run function
ladder_fuels <- pixel_metrics(ctg, ~custom_classification(Z), res = 1)
# Set CRS
terra::crs(ladder_fuels) <- "EPSG:26913"
# Write raster
writeRaster(ladder_fuels, file.path(out_path, "ladder_WKID26913.tif"))


###########################################



end_time <- proc.time() - start_time
# Convert elapsed time to seconds
total_seconds <- end_time["elapsed"]

# Convert to hours, minutes, and seconds
hours <- floor(total_seconds / 3600)
minutes <- floor((total_seconds %% 3600) / 60)
seconds <- round(total_seconds %% 60)

message(sprintf("Ladder fuels took %d hours, %d minutes, and %d seconds to produce and save to file!", hours, minutes, seconds))
```

1st run on UM lab computer:
Ladder fuels took 4 hours, 23 minutes, and 51 seconds to produce and save to file!

2nd run on Waffle:
**Ladder fuels took 1 hours, 23 minutes, and 53 seconds to produce and save to file!**

The diagonal striping pattern in `ladder_fuels` and `zentropy` is due to uneven point density. We can handle this by normalizing the rasters by point density. We will do this in python later, but now, to do this, we need to create a point density raster. See below:

```{r}
start_time <- proc.time()




###########################################
point_density <- grid_density(ctg, res=1)
terra::crs(point_density) <- "EPSG:26913"

writeRaster(point_density, file.path(out_path, "density_WKID26913.tif"))

###########################################



end_time <- proc.time() - start_time
# Convert elapsed time to seconds
total_seconds <- end_time["elapsed"]

# Convert to hours, minutes, and seconds
hours <- floor(total_seconds / 3600)
minutes <- floor((total_seconds %% 3600) / 60)
seconds <- round(total_seconds %% 60)

message(sprintf("Point density took %d hours, %d minutes, and %d seconds to produce and save to file!", hours, minutes, seconds))
```

1st run on UM lab computer:
Point density took 2 hours, 28 minutes, and 32 seconds to produce and save to file!

2nd run on Waffle:
**Point density took 0 hours, 35 minutes, and 35 seconds to produce and save to file!**

Now let's do some canopy cover metrics at various height classes.

```{r}
# Canopy closure less than 2m tall
cc2m    <- function(z, RetNum) {
  return(length(z[z>0 & z<=2 & RetNum==1]) / length(z[RetNum==1]))
}
# Canopy closure 2-4m tall
cc2_4m  <- function(z, RetNum) {
  return(length(z[z>2 & z<=4 & RetNum==1]) / length(z[RetNum==1]))
}
# canopy closure 4-8m tall
cc4_8m  <- function(z, RetNum) {
  return(length(z[z>4 & z<=8 & RetNum==1]) / length(z[RetNum==1]))
}
# canopy closure 8m+ tall (max 40m)
cc8_40m <- function(z, RetNum) {
  return(length(z[z>8 & RetNum==1]) / length(z[RetNum==1]))
}

```

Functions are defined, now we pass them in pixel metrics

```{r}
start_time <- proc.time()




###########################################
cc2m_object <- pixel_metrics(ctg, ~cc2m(Z, ReturnNumber), res=1)
cc2_4m_object <- pixel_metrics(ctg, ~cc2_4m(Z, ReturnNumber), res=1)
cc4_8m_object <- pixel_metrics(ctg, ~cc4_8m(Z, ReturnNumber), res=1)
cc8_40m_object <- pixel_metrics(ctg, ~cc8_40m(Z, ReturnNumber), res=1)

terra::crs(cc2m_object) <- "EPSG:26913"
terra::crs(cc2_4m_object) <- "EPSG:26913"
terra::crs(cc4_8m_object) <- "EPSG:26913"
terra::crs(cc8_40m_object) <- "EPSG:26913"

writeRaster(cc2m_object, file.path(out_path, "cc2m_WKID26913.tif"))
writeRaster(cc2_4m_object, file.path(out_path, "cc2_4m_WKID26913.tif"))
writeRaster(cc4_8m_object, file.path(out_path, "cc4_8m_WKID26913.tif"))
writeRaster(cc8_40m_object, file.path(out_path, "cc8_40m_WKID26913.tif"))

###########################################



end_time <- proc.time() - start_time
# Convert elapsed time to seconds
total_seconds <- end_time["elapsed"]

# Convert to hours, minutes, and seconds
hours <- floor(total_seconds / 3600)
minutes <- floor((total_seconds %% 3600) / 60)
seconds <- round(total_seconds %% 60)

message(sprintf("Canopy closure metrics took %d hours, %d minutes, and %d seconds to produce and save to file!", hours, minutes, seconds))

```

I did not document how long this took on my lab computer.

2nd run on Waffle:
**Canopy closure metrics took 6 hours, 21 minutes, and 58 seconds to produce and save to file!**

```{r}



```
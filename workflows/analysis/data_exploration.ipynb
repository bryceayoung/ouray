{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Ouray County Parcvel Risk\n",
    "**Author:** Bryce A Young  \n",
    "**Created:** 2025-01-17 | \n",
    "**Modified:** 2025-01-17  \n",
    "\n",
    "#### Overview\n",
    "In the notebooks contained under the `data_prep` folder of this repository, we prepared raster, vector, and tabular data for analysis through extensive cleaning. In the `hiz` folder of this repository, the notebooks contain code for finding and summarizing raster values within the HIZ of each home, then appending that to the shapefiles. In this `analysis` folder, we finally get to see what the data is capable of producing.\n",
    "\n",
    "This notebook explores relationships between variables in order to describe them for my thesis. \n",
    "\n",
    "First, let's import the training data. We will import a csv for lighter computation instead of the shapefile. Later, we will join the results to the shapefile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set pandas option to display all columns instead of truncate\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# Import training data\n",
    "train = pd.read_csv('file/path.csv')\n",
    "\n",
    "print('training data shape: ', train.shape)\n",
    "print('training data preview: ')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the realationship of every numeric predictor variable to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up a 5x3 grid\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 20))\n",
    "\n",
    "# Flatten the 2D array of subplots for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Variables 'f6' to 'f20'\n",
    "variables = ['f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20']\n",
    "\n",
    "# Response variable\n",
    "target_variable = 'target'\n",
    "\n",
    "# Create scatter plots for each variable against 'target' in the grid\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.scatterplot(x=train[variable], y=train[target_variable], ax=axes[i])\n",
    "    axes[i].set_title(f'Scatter Plot for {variable} vs. {target_variable}')\n",
    "    axes[i].set_xlabel(variable)\n",
    "    axes[i].set_ylabel(target_variable)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of the continuous data with box and whisker plots using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 20))\n",
    "\n",
    "# Flatten the 2D array of subplots for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Variables 'f6' to 'f20'\n",
    "variables = ['f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20']\n",
    "\n",
    "# Create boxen plots for each variable in the grid\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.boxplot(x=train[variable], ax=axes[i])\n",
    "    axes[i].set_xlabel(variable)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the distribution of categorical variables by printing out their value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['1', '2']\n",
    "\n",
    "for col in cols:\n",
    "    print(train[col].value_counts(normalize=True)) # Normalize will print as a percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a bar chart for each  of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'var1': ['A', 'B', 'A', 'C', 'A', 'B', 'C'],\n",
    "    'var2': ['X', 'X', 'Y', 'Y', 'Z', 'X', 'Z'],\n",
    "    'var3': ['D', 'E', 'D', 'F', 'F', 'E', 'D']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot bar chart subplots\n",
    "def plot_categorical_distributions(df):\n",
    "    # Determine the number of variables\n",
    "    cat_columns = df.select_dtypes(include='object').columns\n",
    "    num_vars = len(cat_columns)\n",
    "    \n",
    "    # Set up subplots\n",
    "    fig, axes = plt.subplots(nrows=num_vars, ncols=1, figsize=(8, num_vars * 3))\n",
    "    if num_vars == 1:  # If only one variable, axes is not a list\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot each variable\n",
    "    for ax, col in zip(axes, cat_columns):\n",
    "        df[col].value_counts().plot(kind='bar', ax=ax, color='#76c7c0', alpha=0.9)\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_xlabel('Categories')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_categorical_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Count plot is another handy visualization tool\n",
    "sns.countplot(data=train, x='col')\n",
    "\n",
    "# OPTIONAL: add hue to break it down by another variable\n",
    "# sns.countplot(data=train, x='col1', hue='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this one is going to be cool. Let's make a heatmap of each categorical variable, showing its correlation to every other variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable correlations - correlation heat map with numbers\n",
    "X = train[['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10',\n",
    "          'f11','f12','f13','f14','f15','f16','f17','f18','f19','f20']]\n",
    "y = train[['target']].copy()\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a heatmap with correlation coefficients\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap with Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this correlation a little more scientifically with chi-squared tests, below. We can also create a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(df['cat1'], df['cat2'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi2: {chi2}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix and heatmap for continuous data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'var1': [1, 2, 3, 4, 5],\n",
    "    'var2': [5, 4, 3, 2, 1],\n",
    "    'var3': [2, 3, 4, 5, 6]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association heatmap for categorical data\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calculate Cramér's V for two categorical variables.\"\"\"\n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "    chi2, _, _, _ = chi2_contingency(contingency_table)\n",
    "    n = contingency_table.sum().sum()\n",
    "    return np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'var1': ['A', 'B', 'A', 'C', 'A', 'B', 'C'],\n",
    "    'var2': ['X', 'X', 'Y', 'Y', 'Z', 'X', 'Z'],\n",
    "    'var3': ['D', 'E', 'D', 'F', 'F', 'E', 'D']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Compute Cramér's V matrix\n",
    "categorical_cols = df.columns\n",
    "matrix = pd.DataFrame(index=categorical_cols, columns=categorical_cols)\n",
    "\n",
    "for col1 in categorical_cols:\n",
    "    for col2 in categorical_cols:\n",
    "        matrix.loc[col1, col2] = cramers_v(df[col1], df[col2])\n",
    "\n",
    "matrix = matrix.astype(float)  # Ensure numeric for heatmap\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title(\"Cramér's V Heatmap (Categorical Variables)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

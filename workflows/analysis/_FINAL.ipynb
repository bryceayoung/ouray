{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Compliation - Ouray County Parcel Risk\n",
    "**Author:** Bryce A Young  \n",
    "**Institution**: University of Montana, National Center for Landscape Fire Analysis\n",
    "\n",
    "**Created:** 2025-03-11 | \n",
    "**Modified:** 2025-03-11  \n",
    "\n",
    "#### Overview\n",
    "This notebook shows the salient points of predictions, clustering, and analysis for the Ouray Parcel Risk project. Consider this the highlight reel of the analysis folder in this repository.\n",
    "\n",
    "This notebook compiles code from `risk_pred.ipynb`, `clustering.ipynb` and `structure_archetypes.ipynb`. Data from those notebooks is used in the present notebook and cleaned further. \n",
    "\n",
    "Final figures are produced and exported for presentations and for use in Chapters 2 and 3 of my masters thesis (risk score predictions and structure archetypes).\n",
    "\n",
    "## Environment Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\_PROJECTS\\\\P001_OurayParcel\\\\ouray'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup environment\n",
    "import os\n",
    "### Directory ###\n",
    "# Repository\n",
    "os.chdir(r'D:/_PROJECTS/P001_OurayParcel/ouray')\n",
    "# Root workspace\n",
    "ws = r'D:/_PROJECTS/P001_OurayParcel'\n",
    "\n",
    "### Data paths ###\n",
    "# Folder where all the data inputs and outputs will live\n",
    "data = os.path.join(ws, 'data')\n",
    "# Scratch folder for intermediate files\n",
    "scratch = os.path.join(data, '_temp')\n",
    "# Any final outputs go here\n",
    "out = os.path.join(data, '_out')\n",
    "# Figures to export\n",
    "figs = os.path.join(out, 'figures')\n",
    "\n",
    "# correct working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Rating Predictions\n",
    "---\n",
    "In this section, I use a random forest classifier to make risk rating predictions. Here is the general workflow:\n",
    "1. Import the most recent data containing reclassified features.\n",
    "2. Re-do some of the one-hot encoding to make sure that the most important features are kept e.g. WUI class 1, wood roof\n",
    "3. Select predictive categorical columns for minimal noise, along with the target columns 'Risk_Rating' and 'Risk_Rating_new'\n",
    "4. Segment training and testing data\n",
    "5. Run the random forest classifier and analyze the results\n",
    "\n",
    "#### **1** Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "full_df = pd.read_csv(os.path.join(out, 'df_feat_clusters.csv'))\n",
    "full_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2** One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataframe to the most salient predictive features\n",
    "df = full_df[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "# NOTE: change OHE drop='first' argument because I don't want to drop these automatically. I will drop the ones I want to later.\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Initialize OHE\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "# NOTE: change OHE cols to only include the ones I want\n",
    "################\n",
    "\n",
    "\n",
    "\n",
    "# OHE cols\n",
    "ohe_cols = ['wui_class', 'tax_ARCH', 'tax_EXW', 'tax_RCVR', 'tax_RSTR']\n",
    "ohe_array = ohe.fit_transform(df[ohe_cols])\n",
    "ohe_df = pd.DataFrame(ohe_array, columns=ohe.get_feature_names_out(ohe_cols))\n",
    "df = pd.concat([df, ohe_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3** Select salient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictive columns (and include target variable)\n",
    "rf_pred_cols = []\n",
    "\n",
    "# Create dataframe from predictive columns\n",
    "pred = df[rf_pred_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4** Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define train-test split function\n",
    "def split_data(df):\n",
    "    X = df.drop(columns=['Risk_Rating'])\n",
    "    y = df['Risk_Rating']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply to categorical data\n",
    "X_train, X_test, y_train, y_test = split_data(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5** Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train_enc, y_train) # Using one-hot encoded variables\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6** Analysis of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-Score)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test3, y_pred3)\n",
    "classes = np.unique(y_test3)  # Get class labels\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train3_enc.columns,\n",
    "    'Importance': clf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, min(12, 0.5 * len(feature_importances))))\n",
    "plt.barh(feature_importances['Feature'], feature_importances['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Random Forest Feature Importance - pred3')\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()  # Highest at top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7** Conclusions\n",
    "One issue with predicting risk ratings is that there are not equal breaks.\n",
    "- 20 <= 'Low' <= 240 (range=220)\n",
    "- 241 <= 'Moderate' <= 305 (range=64)\n",
    "- 306 <= 'High' <= 435 (range=129)\n",
    "- 436 <= 'Very High' <= 505 (range=69)\n",
    "- 506 <= 'Extreme' <= 1000 (range=494)\n",
    "\n",
    "Therefore, we reclassified risk ratings with equal interval breaks, each with a range of 200 points.\n",
    "- 0 <= 'Low' <= 200\n",
    "- 201 <= 'Moderate' <= 400\n",
    "- 401 <= 'High' <= 600\n",
    "- 601 <= 'Very High' <= 800\n",
    "- 801 <= 'Extreme' <= 1000\n",
    "\n",
    "The number of observations per risk rating (original and reclassified) is printed from the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of observations per risk rating\n",
    "print(df['Risk_Rating'].value_counts())\n",
    "print(df['Risk_Rating_new'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
